{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing agentic workflow and function calling in our local RAG setup using LangGraph."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing os module for environment variables\n",
    "import os\n",
    "\n",
    "import langchain_core.documents\n",
    "# import pandas as pd\n",
    "# importing necessary functions from dotenv library\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiate embedding model (Nomic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[-0.014556885,\n 0.042907715,\n -0.19152832,\n -0.026611328,\n 0.04434204,\n -0.021774292,\n 0.04977417,\n 0.025512695,\n 0.041381836,\n 0.0018663406]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "dimensionality : int = 768\n",
    "embed_model = NomicEmbeddings(model=\"nomic-embed-text-v1.5\", dimensionality=dimensionality) # not quite clear yet what specific dimensionality I have to work with\n",
    "embed_model.embed_query(\"My query to look up\")[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate retriever\n",
    " Reminder to clean up retriever responses to output info with less boilerplate formatting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='## Object detection', metadata={'Header 1': 'Possibles networks/algorithms', 'Header 2': 'Object detection', 'source': 'data\\\\computer_science_notes\\\\JumperCV Project.md'}),\n Document(page_content='# Basics of Object Detection  \\nTraining a typical object detection model involves the following steps:  \\n1. Creating ground truth data that contains labels of the bounding box and class corresponding to various objects present in the image.  \\n2. Coming up with mechanisms that scan through the image to identify regions (region proposals) that are likely to contain objects. In this chapter, we will learn about leveraging region proposals generated by a method named **selective search**', metadata={'Header 1': 'Basics of Object Detection', 'source': 'data\\\\computer_science_notes\\\\Basics of Object Detection.md'}),\n Document(page_content='Building a model from scratch should be a consideration only if it gives a considerable boost in accuracy for our specific ouse-case.  \\n### Chapter 7, [[Basics of Object Detection]]  \\n### Chapter 8, [[Advanced Object Detection]]  \\n### Chapter 9, [[Image Segmentation]]', metadata={'Header 2': 'Section 2, Object Classification and Detection', 'source': 'data\\\\computer_science_notes\\\\Modern Computer Vision with PyTorch.md'}),\n Document(page_content=\"In such a scenario, image classification is likely to result in inaccurate results, as the object occupies a smaller portion of the entire image. Object detection comes in handy in this scenario (which we will study in the next chapter).\\n\\nA high-level intuition to solve these problems would be to first divide the input images into smaller grid cells (let's say a 10 x 10 grid) and then identify whether a grid cell contains the object of interest\", metadata={'Header 2': 'Section 2, Object Classification and Detection', 'source': 'data\\\\computer_science_notes\\\\Modern Computer Vision with PyTorch.md'})]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name : str = \"markdown-notes\"\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=index_name,\n",
    "    embedding=embed_model,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4) # top k = 4\n",
    "retriever.invoke(\"object detection\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load our LLM (local LLaMa 3 8b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\"What a great question!\\n\\nThe short answer is: scattering of light by tiny molecules in the atmosphere.\\n\\nHere's a more detailed explanation:\\n\\nWhen sunlight enters Earth's atmosphere, it encounters tiny molecules of gases like nitrogen (N2) and oxygen (O2). These molecules are much smaller than the wavelength of visible light, so they scatter the light in all directions. This is known as Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described the phenomenon in the late 19th century.\\n\\nNow, here's the important part: shorter (blue) wavelengths are scattered more than longer (red) wavelengths. This is because the smaller molecules are more effective at scattering the shorter wavelengths. Think of it like a game of pool: the smaller balls (blue light) bounce around more easily than the larger ones (red light).\\n\\nAs a result, when we look up at the sky, our eyes see the scattered blue light more prominently, making the sky appear blue. The color of the sky can vary depending on atmospheric conditions, like pollution, dust, and water vapor, which can scatter light in different ways. But generally, the blue color is due to the scattering of sunlight by tiny molecules in the atmosphere.\\n\\nFun fact: This same principle is why sunsets often appear more orange or red – the longer wavelengths of light have a harder time being scattered, so they reach our eyes with less interference from the shorter wavelengths!\\n\\nSo, there you have it! The sky is blue because of the scattering of sunlight by tiny molecules in the atmosphere.\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = Ollama(model=\"llama3:8b\",\n",
    "               keep_alive=1, # keep model loaded to gain time\n",
    "               temperature=0,\n",
    "               )\n",
    "\n",
    "model.invoke(\"Why is the sky blue ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For all chains, uncomment invoke lines to test out queries.\n",
    "### Create a Router\n",
    "This agent will evaluate whether we should use the vectorstore or call a websearch based on a query. At first, the objective was to use this router to *complement* our context when judged necessary, but I will start with this approach first.\n",
    "We dictate a JSON output to parse, to guarantee and systematize interpretable answers.\n",
    "Learned info on how to correctly format Llama prompt using special tokens: [https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/). We start with setting the 'system' role to gie a system message, and end with the assistant header to prompt the model to start generation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are dedicated to routing a query inputted by a user, either to a vectorstore or a web search.\n",
      "The vectorstore contains information related to statistical analysis and machine learning concepts and practices.\n",
      "Queries are routed to the vectorstore when they are questions on the aforementioned subjects. Otherwise, route the\n",
      "query to web search. You strictly return a binary choice between 'vectorstore' and 'websearch'. Your output should be a JSON\n",
      "with the only key being 'context_source', nothing else. <|eot_id|>\n",
      "\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Here is the query you need to route: 'object detection technique' <|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are dedicated to routing a query inputted by a user, either to a vectorstore or a web search.\n",
      "The vectorstore contains information related to statistical analysis and machine learning concepts and practices.\n",
      "Queries are routed to the vectorstore when they are questions on the aforementioned subjects. Otherwise, route the\n",
      "query to web search. You strictly return a binary choice between 'vectorstore' and 'websearch'. Your output should be a JSON\n",
      "with the only key being 'context_source', nothing else. <|eot_id|>\n",
      "\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Here is the query you need to route: 'why is the sky blue' <|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "router_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are dedicated to routing a query inputted by a user, either to a vectorstore or a web search.\n",
    "The vectorstore contains information related to statistical analysis and machine learning concepts and practices.\n",
    "Queries are routed to the vectorstore when they are questions on the aforementioned subjects. Otherwise, route the\n",
    "query to web search. You strictly return a binary choice between 'vectorstore' and 'websearch'. Your output should be a JSON\n",
    "with the only key being 'context_source', nothing else. <|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Here is the query you need to route: '{query}' <|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "router_prompt = PromptTemplate.from_template(router_template)\n",
    "router = router_prompt | model | JsonOutputParser()\n",
    "\n",
    "router_toy_query = \"object detection technique\"\n",
    "print(router_prompt.format(query=router_toy_query))\n",
    "# print(router.invoke(input={\"query\": router_toy_query}))\n",
    "\n",
    "router_toy_query2 = \"why is the sky blue\"\n",
    "print('\\n\\n', router_prompt.format(query=router_toy_query2))\n",
    "# print(router.invoke(input={\"query\": router_toy_query2}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create our RAG/websearch response chain\n",
    " For a first iteration of our prompt, it would answer 'I don't know' when I queried 'vacations in Greece in the summer' but would respond with its latent knowledge when I only typed 'vacations in Greece'. From my observation, it was because the top document retrieved had the word 'sky' in it. I needed to be more explicit in my prompt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a virtual assistant strictly designed to provide knowledge based on provided context from a database of documents.\n",
      "Answer the question based on the context below.\n",
      "If you have evaluated that the given context cannot help you provide a related answer, reply 'I don't know' and absolutely nothing else.\n",
      "Don't be too verbose with your answers.<|eot_id|>\n",
      "\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Query: 'object detection technique'\n",
      "Context: [Document(page_content='## Object detection', metadata={'Header 1': 'Possibles networks/algorithms', 'Header 2': 'Object detection', 'source': 'data\\\\computer_science_notes\\\\JumperCV Project.md'}), Document(page_content='# Basics of Object Detection  \\nTraining a typical object detection model involves the following steps:  \\n1. Creating ground truth data that contains labels of the bounding box and class corresponding to various objects present in the image.  \\n2. Coming up with mechanisms that scan through the image to identify regions (region proposals) that are likely to contain objects. In this chapter, we will learn about leveraging region proposals generated by a method named **selective search**', metadata={'Header 1': 'Basics of Object Detection', 'source': 'data\\\\computer_science_notes\\\\Basics of Object Detection.md'}), Document(page_content='The standard approach of MOT is as quoted:\\n```\\nâ€¢ Detection stage: this step is performed by an object detection algorithm, which will output a set of bounding boxes corresponding to the desired objects;\\n\\nâ€¢ Feature extraction/motion prediction stage: the detections are analysed to extract features regarding appearance, motion, interaction', metadata={'Header 1': 'Reference read-throughs', 'Header 2': '[Computer vision for detecting and tracking players in basketball videos, Sara Battelini (Politecnico de Torino) (2020)](https://webthesis.biblio.polito.it/15863/1/tesi.pdf)', 'source': 'data\\\\computer_science_notes\\\\JumperCV Project.md'}), Document(page_content='# [[SSD (Single Shot Detector) approach for object detection|Working details of SSD]]', metadata={'Header 1': '[[SSD (Single Shot Detector) approach for object detection|Working details of SSD]]', 'source': 'data\\\\computer_science_notes\\\\Advanced Object Detection.md'})]\n",
      "Answer:<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a virtual assistant strictly designed to provide knowledge based on provided context from a database of documents.\n",
      "Answer the question based on the context below.\n",
      "If you have evaluated that the given context cannot help you provide a related answer, reply 'I don't know' and absolutely nothing else.\n",
      "Don't be too verbose with your answers.<|eot_id|>\n",
      "\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Query: 'vacations to Greece in the summer'\n",
      "Context: [Document(page_content='2. Fit the model to the randomly chosen data (with homography, take 4 pairs of matching points and compute the homography).\\n3. Count the number M of data points (inliers) that fit the model within a set margin of error/threshold Epsilon.\\n4. Repeat N times.\\n5. Choose the model that has the largest amount of inliers M', metadata={'Header 1': 'New CV concepts', 'Header 2': 'RANSAC algorithm', 'source': 'data\\\\computer_science_notes\\\\JumperCV Project.md'}), Document(page_content=\"## What are region proposals ?  \\n```\\nImagine a hypothetical scenario where the image of interest contains a person and sky in the background. Furthermore, for this scenario, let's assume that there is little change in pixel intensity of the background (sky) and that there is a considerable change in pixel intensity of the foreground (the person). Just from the preceding description itself, we can conclude that there are two primary regions here â€“ one is of the person and the other is of the sky\", metadata={'Header 1': 'Basics of Object Detection', 'Header 2': 'What are region proposals ?', 'source': 'data\\\\computer_science_notes\\\\Basics of Object Detection.md'}), Document(page_content='```\\nIn a class at one high school in Dallas, there are 50 students but only 10 books to give to these students. The sampling interval is fixed by dividing the number of students in the class by the number of books (50/10 = 5). We also need to generate a random number between one and 50 as a random starting point. For example, take the number 18', metadata={'Header 1': 'Part 1, An introduction to statistics', 'Header 2': 'Chapter 1, Sampling and Generalization', 'source': 'data\\\\computer_science_notes\\\\Building Statistical Models in Python.md'}), Document(page_content='## [A Robust and Efficient Framework for Sports-Field Registration (2021)](https://openaccess.thecvf.com/content/WACV2021/papers/Nie_A_Robust_and_Efficient_Framework_for_Sports-Field_Registration_WACV_2021_paper.pdf)  \\nThis paper presents research done by Amazon Prime Video research. It consists of a framework capable of registering sports-fields with real time broadcast video', metadata={'Header 1': 'Reference read-throughs', 'Header 2': '[A Robust and Efficient Framework for Sports-Field Registration (2021)](https://openaccess.thecvf.com/content/WACV2021/papers/Nie_A_Robust_and_Efficient_Framework_for_Sports-Field_Registration_WACV_2021_paper.pdf)', 'source': 'data\\\\computer_science_notes\\\\JumperCV Project.md'})]\n",
      "Answer:<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a virtual assistant strictly designed to provide knowledge based on provided context from a database of documents.\n",
    "Answer the question based on the context below.\n",
    "If you have evaluated that the given context cannot help you provide a related answer, reply 'I don't know' and absolutely nothing else.\n",
    "Don't be too verbose with your answers.<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Query: '{query}'\n",
    "Context: {context}\n",
    "Answer:<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "rag_prompt = PromptTemplate.from_template(rag_template)\n",
    "rag = rag_prompt | model | StrOutputParser()\n",
    "\n",
    "rag_toy_query = \"object detection technique\"\n",
    "print(rag_prompt.format(query=rag_toy_query, context= retriever.invoke(rag_toy_query)))\n",
    "# print(rag.invoke(input={\"query\": rag_toy_query, \"context\" : retriever.invoke(rag_toy_query)}))\n",
    "\n",
    "rag_toy_query_2 = \"vacations to Greece in the summer\"\n",
    "print('\\n\\n',rag_prompt.format(query=rag_toy_query_2, context= retriever.invoke(rag_toy_query_2)))\n",
    "# print(rag.invoke(input={\"query\": rag_toy_query_2, \"context\" : retriever.invoke(rag_toy_query_2)}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create an answer grader\n",
    "We'll establish a chain responsable for evaluating whether a generated response is relevant or not to the original query. For now we won't use this chain to restart a search or redraft."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a grader responsible for evaluating whether an answer is relevant to a given query.\n",
      "You strictly return a binary choice between 'yes' and 'no'. Your output should be a JSON\n",
      "with the only key being 'relevant_answer', nothing else.<|eot_id|>\n",
      "\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Here is the answer:\n",
      "\n",
      " ------- \n",
      "\n",
      "answer_to_grade\n",
      "\n",
      " ------- \n",
      "\n",
      "Here is the query: 'object detection technique'<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a grader responsible for evaluating whether an answer is relevant to a given query.\n",
      "You strictly return a binary choice between 'yes' and 'no'. Your output should be a JSON\n",
      "with the only key being 'relevant_answer', nothing else.<|eot_id|>\n",
      "\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Here is the answer:\n",
      "\n",
      " ------- \n",
      "\n",
      "answer_to_grade2\n",
      "\n",
      " ------- \n",
      "\n",
      "Here is the query: 'vacations to Greece in the summer'<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "grader_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a grader responsible for evaluating whether an answer is relevant to a given query.\n",
    "You strictly return a binary choice between 'yes' and 'no'. Your output should be a JSON\n",
    "with the only key being 'relevant_answer', nothing else.<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Here is the answer:\n",
    "\\n ------- \\n\n",
    "{answer}\n",
    "\\n ------- \\n\n",
    "Here is the query: '{query}'<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "grader_prompt = PromptTemplate.from_template(grader_template)\n",
    "answer_grader = grader_prompt | model | JsonOutputParser()\n",
    "\n",
    "query_for_grading = \"object detection technique\"\n",
    "# answer_to_grade = rag.invoke(input={\"query\": query_for_grading, \"context\" : retriever.invoke(query_for_grading)})\n",
    "print(grader_prompt.format(query=query_for_grading, answer= \"answer_to_grade\"))\n",
    "# print(answer_grader.invoke(input={\"query\": query_for_grading, \"answer\" : answer_to_grade}))\n",
    "\n",
    "\n",
    "query_for_grading_2 = \"vacations to Greece in the summer\"\n",
    "# answer_to_grade2 = rag.invoke(input={\"query\": query_for_grading_2, \"context\" : retriever.invoke(query_for_grading_2)})\n",
    "print('\\n\\n',grader_prompt.format(query=query_for_grading_2, answer= \"answer_to_grade2\"))\n",
    "# print(answer_grader.invoke(input={\"query\": query_for_grading_2, \"answer\" : answer_to_grade2}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement a web search tool\n",
    "We'll use TavilySearchResults."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "web_search_tool = TavilySearchAPIRetriever(k=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a graph state\n",
    "We've made every component of our workflow, we'll represent the relationships between them end exploit them through a graph. Our LangGraph workflow is in three parts: the nodes, the edges, and the graph state.\n",
    "We set up the graph state first. They represent the variables that are passed around at any point when we go through our nodes.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        query: user query\n",
    "        answer: LLM generation\n",
    "        documents: retrieved documents from our rag and the internet\n",
    "        web_search_needed: whether we need a websearch or not\n",
    "        answer_grade: whether the final answer was judged relevant by our grader, True if yes\n",
    "        num_steps: number of steps\n",
    "\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    answer: str\n",
    "    documents: List[str]\n",
    "    relevant_answer: bool\n",
    "    num_steps: int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nodes\n",
    "1. retrieve documents\n",
    "2. websearch\n",
    "3. generate an answer\n",
    "4. grade the answer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def retrieve_documents(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve document from vector store.\n",
    "\n",
    "    :param state: Current state graph\n",
    "    :return: State graph with documents key added\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVING DOCUMENTS FROM VECTOR STORE---\")\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    documents : list[langchain_core.documents.Document] = retriever.invoke(query)\n",
    "    return {\"query\": query, \"documents\": documents, \"num_steps\": int(state[\"num_steps\"]) + 1}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def web_search(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Search for the web with a query and retrieve top k documents.\n",
    "\n",
    "    :param state: Current state graph\n",
    "    :return: State graph with websearch key added\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH FOR ADDITIONAL INFO---\")\n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    web_results : list[langchain_core.documents.Document] = web_search_tool.invoke(query)\n",
    "    if documents is None:\n",
    "        documents = web_results\n",
    "    else:\n",
    "        documents.extend(web_results)\n",
    "\n",
    "    return {\"query\": query, \"documents\": documents, \"num_steps\": int(state[\"num_steps\"]) + 1}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def generate_answer(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Call LLM to generate answer based on query and context.\n",
    "\n",
    "    :param state: Current state graph\n",
    "    :return: State graph with websearch key added\n",
    "    \"\"\"\n",
    "    print(\"---GENERATING LLM ANSWER BASED ON RETRIEVED CONTEXT---\")\n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    answer = rag.invoke(input={\"query\": query, \"context\" : documents})\n",
    "\n",
    "    return {\"query\": query, \"documents\": documents, \"answer\":answer, \"num_steps\": int(state[\"num_steps\"]) + 1}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def grade_answer(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Call LLM to determine if answer is relevant to context or no.\n",
    "\n",
    "    :param state: Current state graph\n",
    "    :return: State graph with websearch key added\n",
    "    \"\"\"\n",
    "    print(\"---GRADING ANSWER BASED ON RELEVANCE TO CONTEXT---\")\n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"documents\"]\n",
    "    answer = state[\"answer\"]\n",
    "\n",
    "    grade : dict = answer_grader.invoke(input={\"query\": query, \"answer\" : answer})\n",
    "    # print(f\"Grade JSON: {grade}\")\n",
    "    assert 'relevant_answer' in grade and grade['relevant_answer'] == 'yes' or 'no', 'LLM response should be a relevant_answer JSON key with yes or no as value'\n",
    "    relevant_answer = grade['relevant_answer'] == 'yes'\n",
    "\n",
    "    print(f\"User query: '{query}'\\n\")\n",
    "    print(f\"\"\"Final answer:\n",
    "    \\n ------- \\n\n",
    "    {answer}\n",
    "    \\n ------- \\n\n",
    "    Was this answer judged relevant ? : {grade['relevant_answer']}\n",
    "    \"\"\")\n",
    "    return {\"query\": query, \"documents\": documents, \"answer\": answer, \"relevant_answer\": relevant_answer, \"num_steps\": int(state[\"num_steps\"]) + 1}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def state_printer(state: dict) -> None:\n",
    "    \"\"\" print current state \"\"\"\n",
    "    print(\"---STATE PRINTER---\")\n",
    "    print(f\"Query = {state['query']}\")\n",
    "    print(f\"Documents = {state['documents']}\")\n",
    "    print(f\"Answer = {state['answer']}\")\n",
    "    print(f\"Relevant answer = {state['relevant_answer']}\")\n",
    "    print(f\"Number of Steps = {state['num_steps']}\")\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conditional Edges\n",
    "Conditional edges establish points at which decisions have to be made. In our case, when choosing to route between websearch and rag retrieval."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def route_to_research_or_rag(state:dict) -> str:\n",
    "    print(\"---ROUTE QUERY---\")\n",
    "    query = state['query']\n",
    "    print(f\"Given query: {query}\\n\")\n",
    "    decision = router.invoke(input={\"query\": query})\n",
    "    print(f\"Decision: {decision}\")\n",
    "    assert 'context_source' in decision and decision['context_source'] == 'vectorstore' or 'websearch', \"LLM response should be a context_source \" \\\n",
    "                                                                                      \"JSON key with vectorstore or websearch as value\"\n",
    "    route = decision['context_source']\n",
    "    print(f\"---ROUTE QUERY TO  {str.upper(route)}---\")\n",
    "    return route"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build the graph\n",
    "#### Add nodes to our StateGraph object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"grade_answer\", grade_answer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Add edges\n",
    "Link nodes together."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# set entry point, normally a single node, but because our graph starts with a conditional routing, we use set_conditional_entry_point with our conditional edge\n",
    "workflow.set_conditional_entry_point(route_to_research_or_rag,\n",
    "                                     {\n",
    "                                         \"websearch\": \"web_search\",\n",
    "                                         \"vectorstore\": \"retrieve_documents\",\n",
    "                                     })\n",
    "\n",
    "workflow.add_edge(\"retrieve_documents\", \"generate_answer\")\n",
    "workflow.add_edge(\"web_search\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", \"grade_answer\")\n",
    "workflow.add_edge(\"grade_answer\", END)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compile the workflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Compile\n",
    "app = workflow.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test our workflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    \"object detection technique\",\n",
    "    \"vacations spots to Greece in the summer\",\n",
    "    \"Explain cross-entropy\",\n",
    "    \"Learning rate\",\n",
    "    \"When was Leonardo De Vinci born ?\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUERY---\n",
      "Given query: vacations spots to Greece in the summer\n",
      "\n",
      "Decision: {'context_source': 'websearch'}\n",
      "---ROUTE QUERY TO  WEBSEARCH---\n",
      "---WEB SEARCH FOR ADDITIONAL INFO---\n",
      "'Finished running: web_search:'\n",
      "---GENERATING LLM ANSWER BASED ON RETRIEVED CONTEXT---\n",
      "'Finished running: generate_answer:'\n",
      "---GRADING ANSWER BASED ON RELEVANCE TO CONTEXT---\n",
      "User query: 'vacations spots to Greece in the summer'\n",
      "\n",
      "Final answer:\n",
      "    \n",
      " ------- \n",
      "\n",
      "    Some popular vacation spots in Greece for the summer include Fourkouvouni, Areti, Schinopi, Fyropotamos, Mandrakia, and Aghios Konstantinos. Klima is also a great spot to take in the sunset.\n",
      "    \n",
      " ------- \n",
      "\n",
      "    Was this answer judged relevant ? : yes\n",
      "    \n",
      "'Finished running: grade_answer:'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# run the agent\n",
    "inputs = {\"query\": QUERIES[1], \"num_steps\":0}\n",
    "for outputs in app.stream(inputs):\n",
    "    for key, value in outputs.items():\n",
    "        pprint(f'Finished running: {key}:')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}